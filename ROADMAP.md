# Roadmap de mcp-ollama-local

## Versiones Futuras

### v1.1.0 (Próxima)
- [ ] Agregar soporte para múltiples modelos en Ollama simultáneamente.
- [ ] Mejorar la interfaz de usuario con temas oscuros y responsivos.
- [ ] Implementar autenticación básica para acceso seguro.

### v1.2.0
- [ ] Expandir herramientas MCP: agregar soporte para ejecución de comandos seguros, acceso a bases de datos locales.
- [ ] Integrar logging avanzado y monitoreo de uso.
- [ ] Soporte para exportar/importar historial de chat.

### v2.0.0
- [ ] Migración a una arquitectura modular con plugins para herramientas MCP.
- [ ] Soporte para modelos de visión (si Ollama lo soporta).
- [ ] API REST completa para integraciones externas.
- [ ] Internacionalización (i18n) para múltiples idiomas.

### Ideas a Largo Plazo
- Integración con otros proveedores de IA locales (ej. llama.cpp).
- Aplicación móvil complementaria.
- Análisis de conversaciones para insights.

Para contribuir al roadmap, abre un issue en el repositorio.